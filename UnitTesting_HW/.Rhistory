source("SM_WP_NewDate.R")
source("SM_WP_NewDate.R")
source("SM_WP_NewDate.R")
source("SMPlot.R")
#Source in the function from a R Script
source("myplot.R")
cus <- sp_data("counties")
#Modularity lessons 4 and 5: I started out by orginizing chunks based on what I knew I had to do- 1) what I would need for input 2) what I would get an an output, 3) type of code I would need to write.
#Modularity lesson 7: by using block headers I was able to come back to the code I wanted to write later and have an idea of the direction I had planned out.
#Load required packages
library(knitr)
library(data.table)
library(ggplot2)
library(data.table)
#Packages for subsetting climate data
library(dplyr)
library(stringr)
#packages for mapping
library(gstat)
library(phylin)
library(maps)
library(sp)
library(ggmap)
library(mapdata)
library(maptools)
library(lattice)
library(plot3D)
knitr::opts_chunk$set(cache=T)
#Modularity lesson 2: Think about goals- I can read a replacement file easily here and won't have to change the code below
#Modularity lesson 3: Revised my code on 03/22/2018 because I noticed errors and found better ways to clean the data
#Import Data
temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
# Remove NA values
temp<-temp[is.finite(temp$data),]
pcpn<-pcpn[is.finite(pcpn$data),]
#***Names of  columns are not the same in temp and pcpn***
# temp data
#subset data using aggregate function
ag1.temp<-aggregate(temp$data, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$data, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds<-c()
#loop
for (counter in 1:nrow(temp))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(temp[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40$lat)<1e-6) & (abs(exrow[2]- gt40$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds<-c(goodinds,counter)
}
}
#throw out the rows of temp that are not in goodinds
temp<-temp[goodinds,]
## Precipitation data
#subset data using aggregate function
ag1.pcpn <- aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=mean)
ag1.pcpn$count <- aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=length)[,3]
gt40p <- ag1.pcpn[ag1.pcpn$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds<-c()
#loop
for (counter in 1:nrow(pcpn))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(pcpn[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40p$lat)<1e-6) & (abs(exrow[2]- gt40p$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds<-c(goodinds,counter)
}
}
#throw out the rows of temp that are not in goodinds
pcpn <- pcpn[goodinds,]
#Linear regression
#Dependent on finding locations with 40+ years of data
#Used to find intercept and slope
#Will plot slopes on a map, larger slope = more warming
# temp data
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40[counter,c("lat","lon")])
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
#find all the rows of temp that match
temp.ws<-temp[temp.row,]
#run linear regression
model<-lm(data~year, temp.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40$slope[counter]<-slope
}
#pcpn data
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40p$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40p))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40p[counter,c("lat","lon")])
pcpn.row<-which((abs(exrow[1]- pcpn$lat)<1e-6) & (abs(exrow[2]-pcpn$lon)<1e-6))
#find all the rows of temp that match
pcpn.ws<-pcpn[pcpn.row,]
#run linear regression
model<-lm(data~year, pcpn.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40p$slope[counter]<-slope
}
# Map of the US
cus.temp<-map("state",".")
points(gt40$lon,gt40$lat)
# http://www.milanor.net/blog/maps-in-r-plotting-data-points-on-a-map/
#Map of Hawaii (no data?)
hi.temp<-map("world","USA:Hawaii")
points(gt40$lon,gt40$lat)
#Map of Alaska
ak.temp<-map("world","USA:Alaska",xlim = c(-180,-120))
points(gt40$lon,gt40$lat)
#Map of Hawaii
hi.pcpn<-map("world","USA:Hawaii")
points(gt40p$lon,gt40p$lat)
#Map of Alaska
ak.temp<-map("world","USA:Alaska",xlim = c(-180,-120))
points(gt40p$lon,gt40p$lat)
# Maps are only showing up with few points, this will probably mess up spatial interpolation if I can't clip properly
# Map of the US
cus.pcpn<-map("state",".")
points(gt40p$lon,gt40p$lat)
#change the col names to match code that I previously wrote for IDW
names(gt40) <- c("y", "x", "value", "count", "slope")
#Check range in the x column
range(gt40$x)
#check range in y column
range(gt40$y)
#Check data spacing for x column
xspacing <- str(unique(gt40$x)) #data spacing in the X direction is 0.25 m (except at the ends)
summary(xspacing)
#check data spacing for z column
yspacing <- diff(unique(gt40$y))
summary(yspacing)
# make a grid
XYGrid <- expand.grid(x=seq(floor(min(gt40$x)),
ceiling(max(gt40$x)),by=.5),
y=seq(floor(max(gt40$y)),
ceiling(min(gt40$y)), by= -.5))
#Run IDW
gt40.idw <- idw(values = gt40[,"slope"],coords = gt40[,c("x","y")], grid = XYGrid)
# add IDW to grid
XYGrid$intep.val <- gt40.idw$Z
#name the third column
# names(gt40)[6] <- "intep.val"
#using level plot to plot IDW
levelplot(intep.val~x+y,XYGrid,col.regions=jet.col(101),asp="iso")
#use spatial points function
##data from gt40, col 2 is x(long) col 1 is y(lat)
##coordinate refrence system (CRS): projection is longitude and latitude and datum is the European Petroleum Survey Group
dsp <- SpatialPoints(gt40[,2:1], proj4string = CRS("+proj=longlat +datum=WGS84"))
dsp <- SpatialPointsDataFrame(dsp, gt40)
cus <- sp_data("counties")
library(sp)
cus <- sp_data("counties")
install.packages(rspatial)
install.packages('rspatial')
library(rspatial)
library("rspatial")
install.packages('rtools')
install.packages('Rtools')
rbPal <- colorRampPalette(c('red','blue'))
View(gt40)
gt40$Col <- rbPal(10)[as.numeric(cut(gt40$slope,breaks = 10))]
# Map of the US
cus.temp<-map("state",".")
points(gt40$lon,gt40$lat, points(gt40$lon,gt40$lat))
points(gt40$lon,gt40$lat,pch = 20,col = gt40$Col)
points(gt40$lon,gt40$lat)
cus.temp<-map("state",".")
points(gt40$lon,gt40$lat,pch = 20,col = gt40$Col)
points(gt40$lon,gt40$lat)
# Map of the US
cus.temp<-map("state",".")
points(gt40$lon,gt40$lat)
# Map of the US
cus.temp<-map("state",".")
points(gt40$lon,gt40$lat)
# http://www.milanor.net/blog/maps-in-r-plotting-data-points-on-a-map/
