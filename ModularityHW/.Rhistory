#find all the rows of temp that match
temp.ws<-temp[temp.row,]
#run linear regression
model<-lm(value~year, temp.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40$slope[counter]<-slope
}
#pcpn data
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40p$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40p))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40p[counter,c("lat","lon")])
pcpn.row<-which((abs(exrow[1]- pcpn$lat)<1e-6) & (abs(exrow[2]-pcpn$lon)<1e-6))
#find all the rows of temp that match
pcpn.ws<-pcpn[pcpn.row,]
#run linear regression
model<-lm(data~year, pcpn.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40p$slope[counter]<-slope
}
#Modularity lessons 4 and 5: I started out by orginizing chunks based on what I knew I had to do- 1) what I would need for input 2) what I would get an an output, 3) type of code I would need to write.
#Modularity lesson 7: by using block headers I was able to come back to the code I wanted to write later and have an idea of the direction I had planned out.
#Load required packages
library(knitr)
library(data.table)
library(ggplot2)
library(data.table)
#Packages for subsetting climate data
library(dplyr)
library(stringr)
#packages for mapping
library(gstat)
library(phylin)
library(maps)
library(sp)
library(ggmap)
library(mapdata)
library(maptools)
knitr::opts_chunk$set(cache=T)
View(temp)
View(gt40)
# Create an empty grid where n is the total number of cells
grd <- as.data.frame(spsample(gt40, "regular", n=50000))
#convert this basic data frame into a spatial points data frame
coordinates(gt40) = ~lat+lon
plot(gt40)
plot(temp$year[temp$variable == "AL_MUSCLE SHOALS REGIONAL AP_c(-87.5997, 34.7441)"], temp$value[temp$variable == "AL_MUSCLE SHOALS REGIONAL AP_c(-87.5997, 34.7441)"], type="b",
xlim=range(temp$year), ylim=range(temp$value))
plot(temp$year[temp$variable == "AL_MUSCLE SHOALS REGIONAL AP_c(-87.5997, 34.7441)"], temp$value[temp$variable == "AL_MUSCLE SHOALS REGIONAL AP_c(-87.5997, 34.7441)"], xlim=range(temp$year), ylim=range(temp$value))
plot(temp$year[temp$variable == "AL_MUSCLE SHOALS REGIONAL AP_c(-87.5997, 34.7441)"], temp$value[temp$variable == "AL_MUSCLE SHOALS REGIONAL AP_c(-87.5997, 34.7441)"], type = l xlim=range(temp$year), ylim=range(temp$value))
plot(temp$year[temp$variable == "AL_MUSCLE SHOALS REGIONAL AP_c(-87.5997, 34.7441)"], temp$value[temp$variable == "AL_MUSCLE SHOALS REGIONAL AP_c(-87.5997, 34.7441)"], type = "l" xlim=range(temp$year), ylim=range(temp$value))
plot(temp$year[temp$variable == "AL_MUSCLE SHOALS REGIONAL AP_c(-87.5997, 34.7441)"], temp$value[temp$variable == "AL_MUSCLE SHOALS REGIONAL AP_c(-87.5997, 34.7441)"], type="l",
xlim=range(temp$year), ylim=range(temp$value))
names(gt40) <- c("X","y","gt40", "count", "slope", "optional")
View(gt40)
#Modularity lessons 4 and 5: I started out by orginizing chunks based on what I knew I had to do- 1) what I would need for input 2) what I would get an an output, 3) type of code I would need to write.
#Modularity lesson 7: by using block headers I was able to come back to the code I wanted to write later and have an idea of the direction I had planned out.
#Load required packages
library(knitr)
library(data.table)
library(ggplot2)
library(data.table)
#Packages for subsetting climate data
library(dplyr)
library(stringr)
#packages for mapping
library(gstat)
library(phylin)
library(maps)
library(sp)
library(ggmap)
library(mapdata)
library(maptools)
knitr::opts_chunk$set(cache=T)
#Modularity lesson 2: Think about goals- I can read a replacement file easily here and won't have to change the code below
#Modularity lesson 3: Revised my code on 03/22/2018 because I noticed errors and found better ways to clean the data
#Import Data
temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
# Remove NA values
temp<-temp[is.finite(temp$value),]
pcpn<-pcpn[is.finite(pcpn$data),]
#***Names of  columns are not the same in temp and pcpn***
# temp data
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds<-c()
#loop
for (counter in 1:nrow(temp))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(temp[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40$lat)<1e-6) & (abs(exrow[2]- gt40$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds<-c(goodinds,counter)
}
}
#throw out the rows of temp that are not in goodinds
temp<-temp[goodinds,]
## Precipitation data
#subset data using aggregate function
ag1.pcpn <- aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=mean)
ag1.pcpn$count <- aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=length)[,3]
gt40p <- ag1.pcpn[ag1.pcpn$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds<-c()
#loop
for (counter in 1:nrow(pcpn))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(pcpn[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40p$lat)<1e-6) & (abs(exrow[2]- gt40p$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds<-c(goodinds,counter)
}
}
#throw out the rows of temp that are not in goodinds
pcpn <- pcpn[goodinds,]
#Linear regression
#Dependent on finding locations with 40+ years of data
#Used to find intercept and slope
#Will plot slopes on a map, larger slope = more warming
# temp data
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40[counter,c("lat","lon")])
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
#find all the rows of temp that match
temp.ws<-temp[temp.row,]
#run linear regression
model<-lm(value~year, temp.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40$slope[counter]<-slope
}
#pcpn data
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40p$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40p))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40p[counter,c("lat","lon")])
pcpn.row<-which((abs(exrow[1]- pcpn$lat)<1e-6) & (abs(exrow[2]-pcpn$lon)<1e-6))
#find all the rows of temp that match
pcpn.ws<-pcpn[pcpn.row,]
#run linear regression
model<-lm(data~year, pcpn.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40p$slope[counter]<-slope
}
View(gt40)
names(gt40) <- c("x", "y", "value", "count", "slope")
#Check range in the x column
range(gt40$x)
#check range in y column
range(gt40$y)
#Check data spacing for x column
diff(unique(gt40$x)) #data spacing in the X direction is 0.25 m (except at the ends)
#check data spacing for z column
diff(unique(gt40$y)) #data spacing in the Z direction is variable- the smaller spacings are close to 0.25 m.
#Check range in the x column
range(gt40$x)
#check range in y column
range(gt40$y)
#Check data spacing for x column
xspacing <- diff(unique(gt40$x)) #data spacing in the X direction is 0.25 m (except at the ends)
summary(xspacing)
#check data spacing for z column
yspacing <- diff(unique(gt40$y))
summary(yspacing)
#use a grid with a spacing of 0.05 m (1/5th of 0.25 m) spanning the range of both variables
XZGrid <- expand.grid(x=seq(-40,50,by=.05),y=seq(0.0004,7.5,by=0.05))
#name the third column
names(gt40)[6] <- "intep.val"
#Run IDW
gt40.idw <- idw(slope~1, ~x+y, gt40, newdata=XZGrid, omax=8, maxdist=3)
#Run IDW
gt40.idw <- idw(slope~1, ~x+y, gt40, newdata=XZGrid)
hix<-seq(-160.24345, -154.80420,by = .1)
hiy<-seq(18.96392, 22.22314, by = .1)
hid1<-expand.grid(x=hix,y=hiy)
#hawaii idw
hi.idw<-phylin::idw(values = gt40[,"slope"],coords = gt40[,c("lat","lon")], grid = hid1)
sp::coordinates(hid1)<- c("x","y")
#convert to spatial points df
hid1$slope<-hi.idw
#Plot result of idw (spatial object) with spplot
spplot(obj = hid1, zcol = hid1@data$Z)
qplot(year, value, data = temp, colour = color)
require(ggplot2)
data(temp)
qplot(year, value, data = temp, colour = color)
plot(temp$year, temp$value, col = temp$variable)
#Modularity lessons 4 and 5: I started out by orginizing chunks based on what I knew I had to do- 1) what I would need for input 2) what I would get an an output, 3) type of code I would need to write.
#Modularity lesson 7: by using block headers I was able to come back to the code I wanted to write later and have an idea of the direction I had planned out.
#Load required packages
library(knitr)
library(data.table)
library(ggplot2)
library(data.table)
#Packages for subsetting climate data
library(dplyr)
library(stringr)
#packages for mapping
library(gstat)
library(phylin)
library(maps)
library(sp)
library(ggmap)
library(mapdata)
library(maptools)
knitr::opts_chunk$set(cache=T)
#Linear regression
#Dependent on finding locations with 40+ years of data
#Used to find intercept and slope
#Will plot slopes on a map, larger slope = more warming
# temp data
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40[counter,c("lat","lon")])
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
#find all the rows of temp that match
temp.ws<-temp[temp.row,]
#run linear regression
model<-lm(value~year, temp.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40$slope[counter]<-slope
}
#Modularity lessons 4 and 5: I started out by orginizing chunks based on what I knew I had to do- 1) what I would need for input 2) what I would get an an output, 3) type of code I would need to write.
#Modularity lesson 7: by using block headers I was able to come back to the code I wanted to write later and have an idea of the direction I had planned out.
#Load required packages
library(knitr)
library(data.table)
library(ggplot2)
library(data.table)
#Packages for subsetting climate data
library(dplyr)
library(stringr)
#packages for mapping
library(gstat)
library(phylin)
library(maps)
library(sp)
library(ggmap)
library(mapdata)
library(maptools)
knitr::opts_chunk$set(cache=T)
#Modularity lesson 2: Think about goals- I can read a replacement file easily here and won't have to change the code below
#Modularity lesson 3: Revised my code on 03/22/2018 because I noticed errors and found better ways to clean the data
#Import Data
temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
# Remove NA values
temp<-temp[is.finite(temp$value),]
pcpn<-pcpn[is.finite(pcpn$data),]
#***Names of  columns are not the same in temp and pcpn***
# temp data
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds<-c()
#loop
for (counter in 1:nrow(temp))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(temp[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40$lat)<1e-6) & (abs(exrow[2]- gt40$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds<-c(goodinds,counter)
}
}
#throw out the rows of temp that are not in goodinds
temp<-temp[goodinds,]
## Precipitation data
#subset data using aggregate function
ag1.pcpn <- aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=mean)
ag1.pcpn$count <- aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=length)[,3]
gt40p <- ag1.pcpn[ag1.pcpn$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds<-c()
#loop
for (counter in 1:nrow(pcpn))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(pcpn[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40p$lat)<1e-6) & (abs(exrow[2]- gt40p$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds<-c(goodinds,counter)
}
}
#throw out the rows of temp that are not in goodinds
pcpn <- pcpn[goodinds,]
#Linear regression
#Dependent on finding locations with 40+ years of data
#Used to find intercept and slope
#Will plot slopes on a map, larger slope = more warming
# temp data
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40[counter,c("lat","lon")])
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
#find all the rows of temp that match
temp.ws<-temp[temp.row,]
#run linear regression
model<-lm(value~year, temp.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40$slope[counter]<-slope
}
#pcpn data
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40p$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40p))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40p[counter,c("lat","lon")])
pcpn.row<-which((abs(exrow[1]- pcpn$lat)<1e-6) & (abs(exrow[2]-pcpn$lon)<1e-6))
#find all the rows of temp that match
pcpn.ws<-pcpn[pcpn.row,]
#run linear regression
model<-lm(data~year, pcpn.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40p$slope[counter]<-slope
}
# Map of the US
cus.temp<-map("state",".")
points(gt40$lon,gt40$lat)
#Map of Hawaii
hi.temp<-map("world","USA:Hawaii")
points(gt40$lon,gt40$lat)
#Map of Alaska
ak.temp<-map("world","USA:Alaska",xlim = c(-180,-120))
points(gt40$lon,gt40$lat)
# Map of the US
cus.pcpn<-map("state",".")
points(gt40p$lon,gt40p$lat)
#Map of Hawaii
hi.pcpn<-map("world","USA:Hawaii")
points(gt40p$lon,gt40p$lat)
#Map of Alaska
ak.temp<-map("world","USA:Alaska",xlim = c(-180,-120))
points(gt40p$lon,gt40p$lat)
View(gt40p)
# temp data
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds<-c()
#loop
for (counter in 1:nrow(temp))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(temp[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40$lat)<1e-6) & (abs(exrow[2]- gt40$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds<-c(goodinds,counter)
}
}
#throw out the rows of temp that are not in goodinds
temp<-temp[goodinds,]
## Precipitation data
#subset data using aggregate function
ag1.pcpn <- aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=mean)
ag1.pcpn$count <- aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=length)[,3]
gt40p <- ag1.pcpn[ag1.pcpn$count>30,]
#setup for () loop
#where we will put the good indicies
goodinds<-c()
#loop
for (counter in 1:nrow(pcpn))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(pcpn[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40p$lat)<1e-6) & (abs(exrow[2]- gt40p$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds<-c(goodinds,counter)
}
}
#throw out the rows of temp that are not in goodinds
pcpn <- pcpn[goodinds,]
#Linear regression
#Dependent on finding locations with 40+ years of data
#Used to find intercept and slope
#Will plot slopes on a map, larger slope = more warming
# temp data
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40[counter,c("lat","lon")])
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
#find all the rows of temp that match
temp.ws<-temp[temp.row,]
#run linear regression
model<-lm(value~year, temp.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40$slope[counter]<-slope
}
#pcpn data
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40p$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40p))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40p[counter,c("lat","lon")])
pcpn.row<-which((abs(exrow[1]- pcpn$lat)<1e-6) & (abs(exrow[2]-pcpn$lon)<1e-6))
#find all the rows of temp that match
pcpn.ws<-pcpn[pcpn.row,]
#run linear regression
model<-lm(data~year, pcpn.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40p$slope[counter]<-slope
}
# Map of the US
cus.pcpn<-map("state",".")
points(gt40p$lon,gt40p$lat)
# Map of the US
cus.temp<-map("state",".")
points(gt40$lon,gt40$lat, col = gt40$slope)
# Map of the US
cus.temp<-map("state",".")
points(gt40$lon,gt40$lat)
# Map of the US
cus.temp<-map("state",".")
points(gt40$lon,gt40$lat, col=factor(gt40$lat))
# Map of the US
cus.temp<-map("state",".")
points(gt40$lon,gt40$lat, col=factor(gt40$value))
# Map of the US
cus.temp<-map("state",".")
points(gt40$lon,gt40$lat, col=factor(gt40$slope))
