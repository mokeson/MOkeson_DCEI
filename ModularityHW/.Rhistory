ag1.pcpn<-aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=mean)
ag1.pcpn$count<-aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=length)[,3]
gt40.pcpn<-ag1.pcpn[ag1.pcpn$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds.pcpn<-c()
#loop
for (counter in 1:nrow(pcpn))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(pcpn[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40.pcpn$lat)<1e-6) & (abs(exrow[2]- gt40.pcpn$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds.pcpn<-c(goodinds.pcpn,counter)
}
}
#throw out the rows of temp that are not in goodinds
pcpn<-pcpn[goodinds.pcpn,]
#Linear regression
#Dependent on finding locations with 40+ years of data
#Used to find intercept and slope
#Will plot slopes on a map, larger slope = more warming
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40.pcpn$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40.pcpn))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40.pcpn[counter,c("lat","lon")])
pcpn.row<-which((abs(exrow[1]- pcpn$lat)<1e-6) & (abs(exrow[2]-pcpn$lon)<1e-6))
#find all the rows of temp that match
pcpn.ws<-pcpn[pcpn.row,]
#run linear regression
model.pcpn<-lm(data~year, pcpn.ws)
slope.pcpn<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40.pcpn$slope.pcpn[counter]<-slope.pcpn
}
#Modularity lesson 2: Think about goals- I can read a replacement file easily here and won't have to change the code below
#Modularity lesson 3: Revised my code on 03/22/2018 because I noticed errors and found better ways to clean the data
#Import Data
temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
temp<-temp[is.finite(temp$value),]
pcpn<-pcpn[is.finite(pcpn$data),]
#***Names of  columns are not the same in temp and pcpn***
#subset data using aggregate function
ag1.pcpn<-aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=mean)
ag1.pcpn$count<-aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=length)[,3]
gt40.pcpn<-ag1.pcpn[ag1.pcpn$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds.pcpn<-c()
#loop
for (counter in 1:nrow(pcpn))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(pcpn[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40.pcpn$lat)<1e-6) & (abs(exrow[2]- gt40.pcpn$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds.pcpn<-c(goodinds.pcpn,counter)
}
}
#throw out the rows of temp that are not in goodinds
pcpn<-pcpn[goodinds.pcpn,]
exrow
#Linear regression
#Dependent on finding locations with 40+ years of data
#Used to find intercept and slope
#Will plot slopes on a map, larger slope = more warming
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40.pcpn$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40.pcpn))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40.pcpn[counter,c("lat","lon")])
pcpn.row<-which((abs(exrow[5]- pcpn$lat)<1e-6) & (abs(exrow[2]-pcpn$lon)<1e-6))
#find all the rows of temp that match
pcpn.ws<-pcpn[pcpn.row,]
#run linear regression
model.pcpn<-lm(data~year, pcpn.ws)
slope.pcpn<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40.pcpn$slope.pcpn[counter]<-slope.pcpn
}
#Linear regression
#Dependent on finding locations with 40+ years of data
#Used to find intercept and slope
#Will plot slopes on a map, larger slope = more warming
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40.pcpn$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40.pcpn))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40.pcpn[counter,c("lat","lon")])
pcpn.row<-which((abs(exrow[1]- pcpn$lat)<1e-6) & (abs(exrow[2]-pcpn$lon)<1e-6))
#find all the rows of temp that match
pcpn.ws<-pcpn[pcpn.row,]
#run linear regression
model.pcpn<-lm(data~year, pcpn.ws)
slope.pcpn<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40.pcpn$slope.pcpn[counter]<-slope.pcpn
}
#Modularity lesson 2: Think about goals- I can read a replacement file easily here and won't have to change the code below
#Modularity lesson 3: Revised my code on 03/22/2018 because I noticed errors and found better ways to clean the data
#Import Data
temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
temp<-temp[is.finite(temp$value),]
pcpn<-pcpn[is.finite(pcpn$data),]
#***Names of  columns are not the same in temp and pcpn***
#subset data using aggregate function
ag1.pcpn<-aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=mean)
ag1.pcpn$count<-aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=length)[,3]
gt40.pcpn<-ag1.pcpn[ag1.pcpn$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds.pcpn<-c()
#loop
for (counter in 1:nrow(pcpn))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(pcpn[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40.pcpn$lat)<1e-6) & (abs(exrow[2]- gt40.pcpn$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds.pcpn<-c(goodinds.pcpn,counter)
}
}
#throw out the rows of temp that are not in goodinds
pcpn<-pcpn[goodinds.pcpn,]
View(pcpn.ws)
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40.pcpn$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40.pcpn))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40.pcpn[counter,c("lat","lon")])
pcpn.row<-which((abs(exrow[1]- pcpn$lat)<1e-6) & (abs(exrow[2]-pcpn$lon)<1e-6))
#find all the rows of temp that match
pcpn.ws<-pcpn[pcpn.row,]
#run linear regression
model.pcpn<-lm(data~year, pcpn.ws)
slope.pcpn<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40.pcpn$slope.pcpn[counter]<-slope.pcpn
}
#Linear regression
#Dependent on finding locations with 40+ years of data
#Used to find intercept and slope
#Will plot slopes on a map, larger slope = more warming
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40.pcpn$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40.pcpn))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40.pcpn[counter,c("lat","lon")])
pcpn.row<-which((abs(exrow[1]- pcpn$lat)<1e-6) & (abs(exrow[2]-pcpn$lon)<1e-6))
#find all the rows of temp that match
pcpn.ws<-pcpn[pcpn.row,]
#run linear regression
model.pcpn<-lm(data~year, pcpn.ws)
slope.pcpn<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40.pcpn$slope.pcpn[counter]<-slope.pcpn
}
View(gt40)
#Map of the US
cus<-map("state",".")
points(gt40$lon,gt40$lat, col = red, cex =0.6)
#Modularity lessons 4 and 5: I started out by orginizing chunks based on what I knew I had to do- 1) what I would need for input 2) what I would get an an output, 3) type of code I would need to write.
#Modularity lesson 7: by using block headers I was able to come back to the code I wanted to write later and have an idea of the direction I had planned out.
#Load required packages
library(knitr)
library(data.table)
library(ggplot2)
#Packages for subsetting climate data
library(dplyr)
library(stringr)
#packages for mapping
library(gstat)
library(phylin)
library(maps)
library(sp)
library(ggmap)
library(mapdata)
library(maptools)
knitr::opts_chunk$set(cache=T)
#Map of Alaska
ak<-map("world","USA:Alaska",xlim = c(-180,-120))
points(gt40$lon,gt40$lat, col = red, cex =0.6)
#Map of Alaska
ak<-map("world","USA:Alaska",xlim = c(-180,-120))
ak+geom_point(data = gt40, aes(x=long, y= lat))
ak+ggplot()+geom_point(data = gt40, aes(x=long, y= lat))
#Map of Alaska
ak<-map_data("world","USA:Alaska",xlim = c(-180,-120))
ggplot()+geom_polygon(data=ak, aes(x=ling, y=lat))+geom_point(data = gt40, aes(x=long, y= lat))
#Map of Alaska
ak<-map("world","USA:Alaska",xlim = c(-180,-120))
map("world","USA:Alaska",xlim = c(-180,-120))
points(gt40$lon,gt40$lat)
#subset data using aggregate function
ag1.pcpn<-aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=mean)
ag1.pcpn$count<-aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=length)[,3]
gt40.pcpn<-ag1.pcpn[ag1.pcpn$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds.pcpn<-c()
#loop
for (counter in 1:nrow(pcpn))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(pcpn[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40.pcpn$lat)<1e-6) & (abs(exrow[2]- gt40.pcpn$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds.pcpn<-c(goodinds.pcpn,counter)
}
}
#throw out the rows of temp that are not in goodinds
pcpn<-pcpn[goodinds.pcpn,]
#Linear regression
#Dependent on finding locations with 40+ years of data
#Used to find intercept and slope
#Will plot slopes on a map, larger slope = more warming
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40.pcpn$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40.pcpn))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40.pcpn[counter,c("lat","lon")])
pcpn.row<-which((abs(exrow[1]- pcpn$lat)<1e-6) & (abs(exrow[2]-pcpn$lon)<1e-6))
#find all the rows of temp that match
pcpn.ws<-pcpn[pcpn.row,]
#run linear regression
model.pcpn<-lm(data~year, pcpn.ws)
slope.pcpn<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40.pcpn$slope.pcpn[counter]<-slope.pcpn
}
##all of the slope calculations are coming out the same, did not do anything different on this part than I did with temp.
#Modularity lessons 4 and 5: I started out by orginizing chunks based on what I knew I had to do- 1) what I would need for input 2) what I would get an an output, 3) type of code I would need to write.
#Modularity lesson 7: by using block headers I was able to come back to the code I wanted to write later and have an idea of the direction I had planned out.
#Load required packages
library(knitr)
library(data.table)
library(ggplot2)
#Packages for subsetting climate data
library(dplyr)
library(stringr)
#packages for mapping
library(gstat)
library(phylin)
library(maps)
library(sp)
library(ggmap)
library(mapdata)
library(maptools)
knitr::opts_chunk$set(cache=T)
#Modularity lesson 2: Think about goals- I can read a replacement file easily here and won't have to change the code below
#Modularity lesson 3: Revised my code on 03/22/2018 because I noticed errors and found better ways to clean the data
#Import Data
temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
temp<-temp[is.finite(temp$value),]
pcpn<-pcpn[is.finite(pcpn$data),]
#***Names of  columns are not the same in temp and pcpn***
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds<-c()
#loop
for (counter in 1:nrow(temp))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(temp[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40$lat)<1e-6) & (abs(exrow[2]- gt40$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds<-c(goodinds,counter)
}
}
#throw out the rows of temp that are not in goodinds
temp<-temp[goodinds,]
#Linear regression
#Dependent on finding locations with 40+ years of data
#Used to find intercept and slope
#Will plot slopes on a map, larger slope = more warming
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40[counter,c("lat","lon")])
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
#find all the rows of temp that match
temp.ws<-temp[temp.row,]
#run linear regression
model<-lm(value~year, temp.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40$slope[counter]<-slope
}
#Map of the US
cus<-map("state",".")
#Map of Hawaii
hi<-map("world","USA:Hawaii")
#Map of Alaska
ak<-
map("world","USA:Alaska",xlim = c(-180,-120))
points(gt40$lon,gt40$lat)
head(temp)
View(temp)
View(pcpn)
#Import Data
temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
#pcpn data has differenf column titles than temp so need to make sure they match for reproducability
names(pcpn) <- c("variable", "name", "lon", "lat", "value", "year")
temp<-temp[is.finite(temp$value),]
pcpn<-pcpn[is.finite(pcpn$data),]
## Precipitation data
#subset data using aggregate function
ag1.pcpn <- aggregate(pcpn$value, by= pcpn[c("lat","lon")],FUN=mean)
#Modularity lesson 2: Think about goals- I can read a replacement file easily here and won't have to change the code below
#Modularity lesson 3: Revised my code on 03/22/2018 because I noticed errors and found better ways to clean the data
#Import Data
temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
#pcpn data has differenf column titles than temp so need to make sure they match for reproducability
names(pcpn) <- c("variable", "name", "lon", "lat", "value", "year")
temp<-temp[is.finite(temp$value),]
pcpn<-pcpn[is.finite(pcpn$data),]
#***Names of  columns are not the same in temp and pcpn***
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
install.packages(""data.table"")
install.packages("data.table")
#Modularity lessons 4 and 5: I started out by orginizing chunks based on what I knew I had to do- 1) what I would need for input 2) what I would get an an output, 3) type of code I would need to write.
#Modularity lesson 7: by using block headers I was able to come back to the code I wanted to write later and have an idea of the direction I had planned out.
#Load required packages
library(knitr)
library(data.table)
library(ggplot2)
library(data.table)
#Packages for subsetting climate data
library(dplyr)
library(stringr)
#packages for mapping
library(gstat)
library(phylin)
library(maps)
library(sp)
library(ggmap)
library(mapdata)
library(maptools)
knitr::opts_chunk$set(cache=T)
head(temp)
#pcpn data has differenf column titles than temp so need to make sure they match for reproducability
setnames(pcpn, old=c("state", "name", "lon", "lat", "data", "year"),
new=c("variable", "name", "lon", "lat", "value", "year"))
temp<-temp[is.finite(temp$value),]
pcpn<-pcpn[is.finite(pcpn$vlaue),]
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
#pcpn data has differenf column titles than temp so need to make sure they match for reproducability
setnames(pcpn, old=c("state", "name", "lon", "lat", "data", "year"),
new=c("variable", "name", "lon", "lat", "value", "year"))
temp<-temp[is.finite(temp$value),]
pcpn<-pcpn[is.finite(pcpn$vlaue),]
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
#Import Data
temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
pcpn<-pcpn[is.finite(pcpn$data),]
#Modularity lesson 2: Think about goals- I can read a replacement file easily here and won't have to change the code below
#Modularity lesson 3: Revised my code on 03/22/2018 because I noticed errors and found better ways to clean the data
#Import Data
temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
# Remove NA values
temp<-temp[is.finite(temp$value),]
pcpn<-pcpn[is.finite(pcpn$data),]
#***Names of  columns are not the same in temp and pcpn***
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds<-c()
#loop
for (counter in 1:nrow(temp))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(temp[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40$lat)<1e-6) & (abs(exrow[2]- gt40$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds<-c(goodinds,counter)
}
}
#throw out the rows of temp that are not in goodinds
temp<-temp[goodinds,]
## Precipitation data
#subset data using aggregate function
ag1.pcpn <- aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=mean)
ag1.pcpn$count <- aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=length)[,5]
ag1.pcpn$count <- aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=length)[,4]
## Precipitation data
#subset data using aggregate function
ag1.pcpn <- aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=mean)
View(ag1.temp)
View(ag1.pcpn)
ag1.pcpn$count <- aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=length)[,3]
gt40p <- ag1.pcpn[ag1.pcpn$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds<-c()
#loop
for (counter in 1:nrow(pcpn))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(pcpn[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40p$lat)<1e-6) & (abs(exrow[2]- gt40p$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds<-c(goodinds,counter)
}
}
#throw out the rows of temp that are not in goodinds
pcpn <- pcpn[goodinds,]
#pcpn data
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40p$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40p))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40p[counter,c("lat","lon")])
pcpn.row<-which((abs(exrow[1]- pcpn$lat)<1e-6) & (abs(exrow[2]-pcpn$lon)<1e-6))
#find all the rows of temp that match
pcpn.ws<-pcpn[pcpn.row,]
#run linear regression
model<-lm(value~data, pcpn.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40p$slope[counter]<-slope
}
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40p))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40p[counter,c("lat","lon")])
pcpn.row<-which((abs(exrow[1]- pcpn$lat)<1e-6) & (abs(exrow[2]-pcpn$lon)<1e-6))
#find all the rows of temp that match
pcpn.ws<-pcpn[pcpn.row,]
#run linear regression
model<-lm(data~year, pcpn.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40p$slope[counter]<-slope
}
