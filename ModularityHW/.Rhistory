class(gt40$lat)
class(exrow[1])
exrow<-as.numeric(temp[counter,c("lat","lon")])
class(exrow[1])
exrow
matches<-which((abs(exrow[1]- gt40$lat)<1e-6) & (abs(exrow[2]- gt40$lon)<1e-6))
matches
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds<-c()
#loop
for (counter in 1:nrow(temp))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(temp[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40$lat)<1e-6) & (abs(exrow[2]- gt40$lon)<1e-6))
if (length(matches)>)
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds<-c()
#loop
for (counter in 1:nrow(temp))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(temp[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40$lat)<1e-6) & (abs(exrow[2]- gt40$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds<-c(goodinds,counter)
}
}
#throw out the rows of temp that are not in goodinds
temp<-temp[goodinds,]
class(c(1,2,3))
x<-c(1,2,3)
x[,4]
gt40$slope<-NA
for(counter in 1:nrow(gt40))
temp.ws<-as.numeric(temp[counter,c("year","variable","value","lat","lon","state","name")])
head(temp.ws)
temp.ws<-temp[counter,c("year","variable","value","lat","lon","state","name")]
temp.ws
for(counter in 1:nrow(gt40))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
if (length(temp.row)>0)
{
#find all the rows of temp that match
temp.ws<-temp[temp.row,]
}
#run linear regression
lm(value~year, temp.ws)
#save slopes in gt40
}
for(counter in 1:nrow(gt40))
gt40$slope<-NA
for(counter in 1:nrow(gt40))
gt40$slope<-NA
class(temp.row)
counter<-1
exrow<-as.numeric(gt40[counter,c("lat","lon")])
exrow
if (length(temp.row)>0)
{}
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
temp.row
temp.ws<-temp[temp.row,]
temp.ws
temp.ws
#Modularity lesson 2: Think about goals- I can read a replacement file easily here and won't have to change the code below
#Modularity lesson 3: Revised my code on 03/22/2018 because I noticed errors and found better ways to clean the data
#Import Data
temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
temp<-temp[is.finite(temp$value),]
pcpn<-pcpn[is.finite(pcpn$data),]
#***Names of  columns are not the same in temp and pcpn***
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds<-c()
#loop
for (counter in 1:nrow(temp))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(temp[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40$lat)<1e-6) & (abs(exrow[2]- gt40$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds<-c(goodinds,counter)
}
}
#throw out the rows of temp that are not in goodinds
temp<-temp[goodinds,]
head(temp)
dim(temp)
counter<-1
gt40$slope<-NA
exrow<-as.numeric(gt40[counter,c("lat","lon")])
exrow
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
temp.row
temp.ws<-temp[temp.row,]
temp.ws
model<-lm(value~year, temp.ws)
model
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
slope
gt40$slope[counter]<-slope
View(gt40)
#Linear regression
#Dependent on finding locations with 40+ years of data
#Used to find intercept and slope
#Will plot slopes on a map, larger slope = more warming
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40[counter,c("lat","lon")])
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
#find all the rows of temp that match
temp.ws<-temp[temp.row,]
#run linear regression
model<-lm(value~year, temp.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40$slope[counter]<-slope
}
#Linear regression
#Dependent on finding locations with 40+ years of data
#Used to find intercept and slope
#Will plot slopes on a map, larger slope = more warming
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40[counter,c("lat","lon")])
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
#find all the rows of temp that match
temp.ws<-temp[temp.row,]
#run linear regression
model<-lm(value~year, temp.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40$slope[counter]<-slope
}
?lm
counter<-1
exrow<-as.numeric(gt40[counter,c("lat","lon")])
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
#find all the rows of temp that match
temp.ws<-temp[temp.row,]
#run linear regression
model<-lm(value~year, temp.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40$slope[counter]<-slope
counter<-2
exrow<-as.numeric(gt40[counter,c("lat","lon")])
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
#find all the rows of temp that match
temp.ws<-temp[temp.row,]
#run linear regression
model<-lm(value~year, temp.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40$slope[counter]<-slope
#Modularity lessons 4 and 5: I started out by orginizing chunks based on what I knew I had to do- 1) what I would need for input 2) what I would get an an output, 3) type of code I would need to write.
#Modularity lesson 7: by using block headers I was able to come back to the code I wanted to write later and have an idea of the direction I had planned out.
#Load required packages
library(knitr)
library(data.table)
library(maps)
library(ggplot2)
library(ggmap)
library(mapdata)
#Packages for subsetting climate data
library(dplyr)
library(stringr)
knitr::opts_chunk$set(cache=T)
map("usa",".")
map("usa","state")
map("usa","stats")
map("usa","states")
map("usa",".")
map("state",".")
map("state", interior = F)
map("state", ".")
map("world", c("USA","alaska","hawaii"))
map("world", c("alaska","hawaii","USA"))
map("states", c("alaska","hawaii","USA"))
map("states", c("alaska","hawaii"))
world
map("world", c("alaska","hawaii","USA"))
map("states",".")
map("state",".")
map("world", c("alaska","hawaii","USA"))
#Modularity lessons 4 and 5: I started out by orginizing chunks based on what I knew I had to do- 1) what I would need for input 2) what I would get an an output, 3) type of code I would need to write.
#Modularity lesson 7: by using block headers I was able to come back to the code I wanted to write later and have an idea of the direction I had planned out.
#Load required packages
library(knitr)
library(data.table)
library(maps)
library(ggplot2)
library(ggmap)
library(mapdata)
#Packages for subsetting climate data
library(dplyr)
library(stringr)
knitr::opts_chunk$set(cache=T)
map("world", c("alaska","hawaii","USA"))
map("state",".")
state.name
map("state",regions = state.name)
map("world",regions = state.name)
map("state",".")
map("world", c("alaska","hawaii"))
map("world","alaska")
map("world",regions = "alaska")
map("world",c("alaska", "USA"))
map("world",".")
KS<-map("state","kansas")
KS
map("world","USA")
map("world","USA",xlim = c(-180,-60))
install.packages("gstat")
library(gstat)
?idw
US<-map("world","USA",xlim = c(-180,-60))
US
cus<-map("state",".")
ak<-map(state,"alaska")
ak<-map(world,"alaska")
ak<-map("state","alaska")
ak<-map("state","alaska",xlim = c(-180,-60))
help(map)
ak<-map("usa","alaska")
data(stateMapEnv)
stateMapEnv
ak<-map("usa","ak")
ak<-map("usa","alaska")
state()
maps::state
ak<-map("state","kansas")
ak<-map("state","hawaii")
ak<-map("USA","hawaii")
data("usaMapEnv")
ak<-map("USA","hawaii")
ak<-map("world","USA:Alaska",xlim = c(-180,-60))
ak<-map("world","USA:Alaska",xlim = c(-180,-70))
ak<-map("world","USA:Alaska",xlim = c(-180,-100))
ak<-map("world","USA:Alaska",xlim = c(-180,-120))
hi<-map("world","USA:Hawaii")
hi
hix<-seq(-160.24345 -154.80420,by = .1)
hiy<-seq(18.96392   22.22314, by = .1)
hix<-seq(-160.24345, -154.80420,by = .1)
hiy<-seq(18.96392, 22.22314, by = .1)
hid1<-expand.grid(x=hix,y=hiy)
hid1
?idw
idw(slope~lat+lon, gt40,hid1)
idw(gt40$slope~gt40$lat+gt40$lon, gt40,hid1)
install.packages("phylin")
library(phylin)
hi.idw<-phylin::idw(values = gt40[,"slope"],coords = gt40[,c("lat","lon")], grid = hid1)
hi.idw
install.packages(sp)
install.packages("sp")
install.packages("sp")
library(sp)
install.packages("sp")
library(sp)
install.packages("sp")
library(sp)
View(hid1)
sp::coordinates(hid1)<- c("lon","lat")
sp::coordinates(hid1)<- c("x","y")
hid1$slope<-hi.idw
spplot(obj = hid1, zcol = "slope")
spplot(obj = hid1, zcol = slope)
spplot(obj = hid1, zcol = hid1$slope)
spplot(obj = hid1, zcol = hid1$z)
?spplot
spplot(obj = hid1, zcol = hid1$@data$z)
hid1@data
hid1@data$Z
spplot(obj = hid1, zcol = hid1@data$z)
spplot(obj = hid1, zcol = hid1@data$Z)
#Modularity lessons 4 and 5: I started out by orginizing chunks based on what I knew I had to do- 1) what I would need for input 2) what I would get an an output, 3) type of code I would need to write.
#Modularity lesson 7: by using block headers I was able to come back to the code I wanted to write later and have an idea of the direction I had planned out.
#Load required packages
library(knitr)
library(data.table)
library(ggplot2)
#Packages for subsetting climate data
library(dplyr)
#Modularity lesson 2: Think about goals- I can read a replacement file easily here and won't have to change the code below
#Modularity lesson 3: Revised my code on 03/22/2018 because I noticed errors and found better ways to clean the data
#Import Data
temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
temp<-temp[is.finite(temp$value),]
pcpn<-pcpn[is.finite(pcpn$data),]
#***Names of  columns are not the same in temp and pcpn***
install.packages(dplyr)
install.packages("dplyr")
library(dplyr)
#Modularity lesson 2: Think about goals- I can read a replacement file easily here and won't have to change the code below
#Modularity lesson 3: Revised my code on 03/22/2018 because I noticed errors and found better ways to clean the data
#Import Data
temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
temp<-temp[is.finite(temp$value),]
pcpn<-pcpn[is.finite(pcpn$data),]
#***Names of  columns are not the same in temp and pcpn***
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds<-c()
#loop
for (counter in 1:nrow(temp))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(temp[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40$lat)<1e-6) & (abs(exrow[2]- gt40$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds<-c(goodinds,counter)
}
}
#throw out the rows of temp that are not in goodinds
temp<-temp[goodinds,]
View(temp)
#Linear regression
#Dependent on finding locations with 40+ years of data
#Used to find intercept and slope
#Will plot slopes on a map, larger slope = more warming
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40[counter,c("lat","lon")])
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
#find all the rows of temp that match
temp.ws<-temp[temp.row,]
#run linear regression
model<-lm(value~year, temp.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40$slope[counter]<-slope
}
View(temp)
View(temp.na)
cus<-map("state",".")
#Map of Hawaii
hi<-map("world","USA:Hawaii")
#Map of Alaska
ak<-map("world","USA:Alaska",xlim = c(-180,-120))
library(gstat)
install.packages("gstat","phylin","maps","sp","ggmap","mapdata")
install.packages("gstat")
install.packages("phylin")
install.packages("sp")
install.packages("ggmap")
install.packages("mapdata")
library(gstat)
library(phylin)
library(maps)
library(sp)
library(ggmap)
library(mapdata)
#Modularity lesson 2: Think about goals- I can read a replacement file easily here and won't have to change the code below
#Modularity lesson 3: Revised my code on 03/22/2018 because I noticed errors and found better ways to clean the data
#Import Data
temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
temp<-temp[is.finite(temp$value),]
pcpn<-pcpn[is.finite(pcpn$data),]
#***Names of  columns are not the same in temp and pcpn***
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds<-c()
#loop
for (counter in 1:nrow(temp))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(temp[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40$lat)<1e-6) & (abs(exrow[2]- gt40$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds<-c(goodinds,counter)
}
}
#throw out the rows of temp that are not in goodinds
temp<-temp[goodinds,]
#Linear regression
#Dependent on finding locations with 40+ years of data
#Used to find intercept and slope
#Will plot slopes on a map, larger slope = more warming
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40[counter,c("lat","lon")])
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
#find all the rows of temp that match
temp.ws<-temp[temp.row,]
#run linear regression
model<-lm(value~year, temp.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40$slope[counter]<-slope
}
#Map of the US
cus<-map("state",".")
#Map of Hawaii
hi<-map("world","USA:Hawaii")
#Map of Alaska
ak<-map("world","USA:Alaska",xlim = c(-180,-120))
View(gt40)
install.packages("maptools")
library(maptools)
#grid for hawaii
hix<-seq(-160.24345, -154.80420,by = .1)
hiy<-seq(18.96392, 22.22314, by = .1)
hid1<-expand.grid(x=hix,y=hiy)
#hawaii idw
hi.idw<-phylin::idw(values = gt40[,"slope"],coords = gt40[,c("lat","lon")], grid = hid1)
#slopes as a function of coordinates
sp::coordinates(hid1)<- c("x","y")
#convert to spatial points df
hid1$slope<-hi.idw
#Plot result of idw (spatial object) with spplot
spplot(obj = hid1, zcol = hid1@data$Z)
hid1<-as.data.frame(expand.grid(x=hix,y=hiy))
#hawaii idw
hi.idw<-phylin::idw(values = gt40[,"slope"],coords = gt40[,c("lat","lon")], grid = hid1)
#slopes as a function of coordinates
sp::coordinates(hid1)<- c("x","y")
#convert to spatial points df
hid1$slope<-hi.idw
#Plot result of idw (spatial object) with spplot
spplot(obj = hid1, zcol = hid1@data$Z)
hid1<-expand.grid(x=hix,y=hiy)
#hawaii idw
hi.idw<-phylin::idw(values = gt40[,"slope"],coords = gt40[,c("lat","lon")], grid = hid1)
#slopes as a function of coordinates
sp::coordinates(hid1)<- c("x","y")
#convert to spatial points df
hid1$slope<-hi.idw
#Plot result of idw (spatial object) with spplot
spplot(obj = hid1, zcol = hid1$data$Z)
#Plot result of idw (spatial object) with spplot
spplot(obj = hid1, zcol = "hid1@data$Z")
#Plot result of idw (spatial object) with spplot
spplot(obj = hid1, zcol = "data$Z")
View(hid1)
install.packages(automap)
install.packages("automap")
library(automap)
loadMeuse()
