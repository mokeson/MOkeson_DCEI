#Subset data
#Eliminating na values
temp.na<-na.omit(dt.temp)
pcpn.na<-na.omit(dt.pcpn)
#Eliminate locations w/ fewer than 40 years of data
temp.40<-subset(temp.na, table(temp.na$state, temp.na$name)>40)
#Convert data
dt.temp <- data.table(Temp)
dt.pcpn<- data.table(Pcpn)
#Modularize lesson: temp and precip to aviod copy and pasting
#Don't quite know how to use this in my code
#Use modularity lesson 3: Revise code
dt.list<-list(dt.temp,dt.pcpn)
#Locating stations
loc<-c("state","name","lat","lon")
#Subset data
#Eliminating na values
temp.na<-na.omit(dt.temp)
pcpn.na<-na.omit(dt.pcpn)
#Eliminate locations w/ fewer than 40 years of data
temp.40<-temp.na[with(temp.na,as.logical(ave(state,name,
FUN = function(x) length(x)>2))),]
#Modularity lessons 4 and 5: I started out by orginizing chunks based on what I knew I had to do- 1) what I would need for input 2) what I would get an an output, 3) type of code I would need to write.
#Modularity lesson 7: by using block headers I was able to come back to the code I wanted to write later and have an idea of the direction I had planned out.
#Load required packages
library(knitr)
library(data.table)
library(maps)
library(ggplot2)
library(ggmap)
library(mapdata)
knitr::opts_chunk$set(cache=T)
#Modularity lesson 2: Think about goals- I can read a replacement file easily here and won't have to change the code below
#Modularity lesson 3: Revised my code on 03/22/2018 because I noticed errors and found better ways to clean the data
#Import Data
dt.temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
dt.pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
#Modularity lesson 8: several commented blocks
#
# #Convert data
# dt.temp <- data.table(Temp)
# dt.pcpn<- data.table(Pcpn)
#List of df
dt.list<-list(dt.temp,dt.pcpn)
#Locating stations
loc<-c("lat","lon")
#subset data using aggregate function
#I think there is a way to ommit na values in this step so I can eliminate the previous chunk
ag1.temp<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=mean)
View(ag1.temp)
#subset data using aggregate function
#I think there is a way to ommit na values in this step so I can eliminate the previous chunk
ag1.temp<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=length)[,3]
#subset data using aggregate function
#I think there is a way to ommit na values in this step so I can eliminate the previous chunk
ag1.temp<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count<40,]
View(gt40)
#subset data using aggregate function
#I think there is a way to ommit na values in this step so I can eliminate the previous chunk
ag1.temp<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#subset data using aggregate function
#I think there is a way to ommit na values in this step so I can eliminate the previous chunk
ag1.temp<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon","state")],FUN=mean)
ag1.temp$count<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon","state")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#subset data using aggregate function
#I think there is a way to ommit na values in this step so I can eliminate the previous chunk
ag1.temp<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
View(dt.temp)
temp.na<-na.omit(dt.temp)
pcpn.na<-na.omit(dt.pcpn)
ag1.temp<-aggregate(temp.na$value, by= temp.na[c("lat","lon")],FUN=mean)
#subset data using aggregate function
#I think there is a way to ommit na values in this step so I can eliminate the previous chunk
ag1.temp<-aggregate(temp.na$value, by= temp.na[c("year","lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=length)[,3]
#subset data using aggregate function
#I think there is a way to ommit na values in this step so I can eliminate the previous chunk
ag1.temp<-aggregate(temp.na$value, by= temp.na[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=length)[,3]
#subset data using aggregate function
#I think there is a way to ommit na values in this step so I can eliminate the previous chunk
ag1.temp<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#subset data using aggregate function
ag1.temp<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
gt40.spl<-lapply(gt40, function(x) split(x,paste(x$lat,x$lon)))
#subset data using aggregate function
ag1.temp<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
gt40.spl<-lapply(gt40, function(x) split(x,paste(gt40$lat,gt40$lon)))
head(gt40.spl)
#Modularity lessons 4 and 5: I started out by orginizing chunks based on what I knew I had to do- 1) what I would need for input 2) what I would get an an output, 3) type of code I would need to write.
#Modularity lesson 7: by using block headers I was able to come back to the code I wanted to write later and have an idea of the direction I had planned out.
#Load required packages
library(knitr)
library(data.table)
library(maps)
library(ggplot2)
library(ggmap)
library(mapdata)
#Packages for subsetting climate data
library(dplyr)
library(stringr)
knitr::opts_chunk$set(cache=T)
#Modularity lesson 2: Think about goals- I can read a replacement file easily here and won't have to change the code below
#Modularity lesson 3: Revised my code on 03/22/2018 because I noticed errors and found better ways to clean the data
#Import Data
temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
mean.temp<- group_by((lat, lon) %>%
#subset data using aggregate function
ag1.temp<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
mean.temp<- group_by((temp$lat,temp$lon) %>%
#subset data using aggregate function
ag1.temp<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(dt.temp$value, by= dt.temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
mean.temp<- group_by((temp$name) %>%
summarise(mean.temp = mean(temp$value,ma.rm=T)))
mean.temp<- group_by((temp$name) %>% summarise(mean.temp = mean(temp$value,ma.rm=T)))
library(data.table)
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#Modularity lessons 4 and 5: I started out by orginizing chunks based on what I knew I had to do- 1) what I would need for input 2) what I would get an an output, 3) type of code I would need to write.
#Modularity lesson 7: by using block headers I was able to come back to the code I wanted to write later and have an idea of the direction I had planned out.
#Load required packages
library(knitr)
library(data.table)
library(maps)
library(ggplot2)
library(ggmap)
library(mapdata)
#Packages for subsetting climate data
library(dplyr)
library(stringr)
knitr::opts_chunk$set(cache=T)
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
gt40.splt<- group_by(temp,temp$variable) %>%
summarise(mean_temp = mean(temp$value,na.rm = T))
View(gt40.splt)
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#Looked up new approach but this output gives me the same value for each station
gt40.splt<- group_by(temp, variable) %>%
summarise(mean_temp = mean(value,na.rm = T))
View(ag1.temp)
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#Looked up new approach but this output gives me the same value for each station
gt40.splt<- group_by(temp, variable) %>%
summarise(mean_temp = mean(value,na.rm = T))
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-na.omit(ag1.temp)
View(gt40)
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
gt40.na<-na.omit(gt40)
View(gt40.na)
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")])
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
gt40.na<-na.omit(gt40)
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count<40,]
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#Modularity lessons 4 and 5: I started out by orginizing chunks based on what I knew I had to do- 1) what I would need for input 2) what I would get an an output, 3) type of code I would need to write.
#Modularity lesson 7: by using block headers I was able to come back to the code I wanted to write later and have an idea of the direction I had planned out.
#Load required packages
library(knitr)
library(data.table)
library(maps)
library(ggplot2)
library(ggmap)
library(mapdata)
#Packages for subsetting climate data
library(dplyr)
library(stringr)
knitr::opts_chunk$set(cache=T)
#Modularity lesson 2: Think about goals- I can read a replacement file easily here and won't have to change the code below
#Modularity lesson 3: Revised my code on 03/22/2018 because I noticed errors and found better ways to clean the data
#Import Data
temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
View(ag1.temp)
View(gt40)
x<-c(1,2,3,4,5,6,7,8,9)
which(x>4)
x<-c(23,46,79,10,23,41,78)
which(x>50)
which(x>50 && x<70)
which(x>50 && x<79)
which(x>50 & x<79)
matches<-which(x>50 & x<51)
matches
length(matches)
#Modularity lessons 4 and 5: I started out by orginizing chunks based on what I knew I had to do- 1) what I would need for input 2) what I would get an an output, 3) type of code I would need to write.
#Modularity lesson 7: by using block headers I was able to come back to the code I wanted to write later and have an idea of the direction I had planned out.
#Load required packages
library(knitr)
library(data.table)
library(maps)
library(ggplot2)
library(ggmap)
library(mapdata)
#Packages for subsetting climate data
library(dplyr)
library(stringr)
knitr::opts_chunk$set(cache=T)
#Modularity lesson 2: Think about goals- I can read a replacement file easily here and won't have to change the code below
#Modularity lesson 3: Revised my code on 03/22/2018 because I noticed errors and found better ways to clean the data
#Import Data
temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
goodinds<-c()
for (counter in 1:nrow(temp))
{
#extract lat and lon for row counter of temp
exrow<-temp[counter,c("lat","lon")]
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((exrow[1]== gt40$lat) & (exrow[2]== gt40$lon))
if (length(matches)>0)
{
#add counter to goodinds
goodinds<-c(goodinds,counter)
}
}
#throw out the rows of temp that are not in goodinds
temp<-temp[goodinds,]
View(temp)
#Modularity lessons 4 and 5: I started out by orginizing chunks based on what I knew I had to do- 1) what I would need for input 2) what I would get an an output, 3) type of code I would need to write.
#Modularity lesson 7: by using block headers I was able to come back to the code I wanted to write later and have an idea of the direction I had planned out.
#Load required packages
library(knitr)
library(data.table)
library(maps)
library(ggplot2)
library(ggmap)
library(mapdata)
#Packages for subsetting climate data
library(dplyr)
library(stringr)
knitr::opts_chunk$set(cache=T)
#Modularity lesson 2: Think about goals- I can read a replacement file easily here and won't have to change the code below
#Modularity lesson 3: Revised my code on 03/22/2018 because I noticed errors and found better ways to clean the data
#Import Data
temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds<-c()
counter<-1
exrow<-temp[counter,c("lat","lon")]
matches<-which((exrow[1]== gt40$lat) & (exrow[2]== gt40$lon))
exrow
matches
matches<-which((abs(exrow[1]- gt40$lat)<1e-6) & (abs(exrow[2]- gt40$lon)<1e-6))
matches
exrow(1)
exrow[1]
min(abs(exrow[1]-gt40$lat))
gt40$lat
class(gt40$lat)
class(exrow[1])
exrow<-as.numeric(temp[counter,c("lat","lon")])
class(exrow[1])
exrow
matches<-which((abs(exrow[1]- gt40$lat)<1e-6) & (abs(exrow[2]- gt40$lon)<1e-6))
matches
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds<-c()
#loop
for (counter in 1:nrow(temp))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(temp[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40$lat)<1e-6) & (abs(exrow[2]- gt40$lon)<1e-6))
if (length(matches)>)
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds<-c()
#loop
for (counter in 1:nrow(temp))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(temp[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40$lat)<1e-6) & (abs(exrow[2]- gt40$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds<-c(goodinds,counter)
}
}
#throw out the rows of temp that are not in goodinds
temp<-temp[goodinds,]
class(c(1,2,3))
x<-c(1,2,3)
x[,4]
gt40$slope<-NA
for(counter in 1:nrow(gt40))
temp.ws<-as.numeric(temp[counter,c("year","variable","value","lat","lon","state","name")])
head(temp.ws)
temp.ws<-temp[counter,c("year","variable","value","lat","lon","state","name")]
temp.ws
for(counter in 1:nrow(gt40))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
if (length(temp.row)>0)
{
#find all the rows of temp that match
temp.ws<-temp[temp.row,]
}
#run linear regression
lm(value~year, temp.ws)
#save slopes in gt40
}
for(counter in 1:nrow(gt40))
gt40$slope<-NA
for(counter in 1:nrow(gt40))
gt40$slope<-NA
class(temp.row)
counter<-1
exrow<-as.numeric(gt40[counter,c("lat","lon")])
exrow
if (length(temp.row)>0)
{}
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
temp.row
temp.ws<-temp[temp.row,]
temp.ws
temp.ws
#Modularity lesson 2: Think about goals- I can read a replacement file easily here and won't have to change the code below
#Modularity lesson 3: Revised my code on 03/22/2018 because I noticed errors and found better ways to clean the data
#Import Data
temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
temp<-temp[is.finite(temp$value),]
pcpn<-pcpn[is.finite(pcpn$data),]
#***Names of  columns are not the same in temp and pcpn***
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#setup for () loop
#where we will put the good indicies
goodinds<-c()
#loop
for (counter in 1:nrow(temp))
{
#extract lat and lon for row counter of temp
exrow<-as.numeric(temp[counter,c("lat","lon")])
#See if it matches any of the lat lon from gt40, if it does add counter into goodinds
matches<-which((abs(exrow[1]- gt40$lat)<1e-6) & (abs(exrow[2]- gt40$lon)<1e-6))
if (length(matches)>0)
{
#add counter to goodinds
goodinds<-c(goodinds,counter)
}
}
#throw out the rows of temp that are not in goodinds
temp<-temp[goodinds,]
head(temp)
dim(temp)
counter<-1
gt40$slope<-NA
exrow<-as.numeric(gt40[counter,c("lat","lon")])
exrow
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
temp.row
temp.ws<-temp[temp.row,]
temp.ws
model<-lm(value~year, temp.ws)
model
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
slope
gt40$slope[counter]<-slope
View(gt40)
#Linear regression
#Dependent on finding locations with 40+ years of data
#Used to find intercept and slope
#Will plot slopes on a map, larger slope = more warming
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40[counter,c("lat","lon")])
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
#find all the rows of temp that match
temp.ws<-temp[temp.row,]
#run linear regression
model<-lm(value~year, temp.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40$slope[counter]<-slope
}
#Linear regression
#Dependent on finding locations with 40+ years of data
#Used to find intercept and slope
#Will plot slopes on a map, larger slope = more warming
#prepare rec. for saving slopes
#could use gt40, would need new column
gt40$slope<-NA
#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40))
{
#extract data from each weather station in new temp df
#df with same columns as temp but only the rows for the WS on at this point in loop
#calls the numbers of the rows that are for the ws at each step of the loop
exrow<-as.numeric(gt40[counter,c("lat","lon")])
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
#find all the rows of temp that match
temp.ws<-temp[temp.row,]
#run linear regression
model<-lm(value~year, temp.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40$slope[counter]<-slope
}
?lm
counter<-1
exrow<-as.numeric(gt40[counter,c("lat","lon")])
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
#find all the rows of temp that match
temp.ws<-temp[temp.row,]
#run linear regression
model<-lm(value~year, temp.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40$slope[counter]<-slope
counter<-2
exrow<-as.numeric(gt40[counter,c("lat","lon")])
temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
#find all the rows of temp that match
temp.ws<-temp[temp.row,]
#run linear regression
model<-lm(value~year, temp.ws)
slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
#save slopes in gt40
gt40$slope[counter]<-slope
