---
title: "Okeson_Assignment2"
author: "Morgan Okeson"
date: "February 14, 2018"
output: html_document
---

<!---Chunk for prep--->
```{r echo=F}
#Modularity lessons 4 and 5: I started out by orginizing chunks based on what I knew I had to do- 1) what I would need for input 2) what I would get an an output, 3) type of code I would need to write.
#Modularity lesson 7: by using block headers I was able to come back to the code I wanted to write later and have an idea of the direction I had planned out. 

#Load required packages
library(knitr)
library(data.table)
library(ggplot2)
library(data.table)

#Packages for subsetting climate data
library(dplyr)
library(stringr)

#packages for mapping
library(gstat)
library(phylin)
library(maps)
library(sp)
library(ggmap)
library(mapdata)
library(maptools)

knitr::opts_chunk$set(cache=T)

```

<!---Chunk for loading the data and removing NA--->
```{r echo=F, cache=T}
#Modularity lesson 2: Think about goals- I can read a replacement file easily here and won't have to change the code below
#Modularity lesson 3: Revised my code on 03/22/2018 because I noticed errors and found better ways to clean the data

#Import Data
temp<-readRDS(file="./Data/USAAnnualTemp1950_2016.rds")
pcpn<-readRDS(file="./Data/USAAnnualPcpn1950_2016.rds")
# Remove NA values
temp<-temp[is.finite(temp$value),]
pcpn<-pcpn[is.finite(pcpn$data),]
  #***Names of  columns are not the same in temp and pcpn***
```

<!---Chunk for subsetting the data--->
```{r echo=F, cache=T}
# temp data
#subset data using aggregate function
ag1.temp<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=mean)
ag1.temp$count<-aggregate(temp$value, by= temp[c("lat","lon")],FUN=length)[,3]
gt40<-ag1.temp[ag1.temp$count>40,]
#setup for () loop
  #where we will put the good indicies
goodinds<-c()
  #loop
for (counter in 1:nrow(temp))
{
  #extract lat and lon for row counter of temp
  exrow<-as.numeric(temp[counter,c("lat","lon")])
  
  #See if it matches any of the lat lon from gt40, if it does add counter into goodinds
  matches<-which((abs(exrow[1]- gt40$lat)<1e-6) & (abs(exrow[2]- gt40$lon)<1e-6))
  if (length(matches)>0)
  {
    #add counter to goodinds
    goodinds<-c(goodinds,counter)
  }
}
#throw out the rows of temp that are not in goodinds
temp<-temp[goodinds,]

## Precipitation data
#subset data using aggregate function
ag1.pcpn <- aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=mean)
ag1.pcpn$count <- aggregate(pcpn$data, by= pcpn[c("lat","lon")],FUN=length)[,3]
gt40p <- ag1.pcpn[ag1.pcpn$count>40,]
#setup for () loop
  #where we will put the good indicies
goodinds<-c()
  #loop
for (counter in 1:nrow(pcpn))
{
  #extract lat and lon for row counter of temp
  exrow<-as.numeric(pcpn[counter,c("lat","lon")])
  
  #See if it matches any of the lat lon from gt40, if it does add counter into goodinds
  matches<-which((abs(exrow[1]- gt40p$lat)<1e-6) & (abs(exrow[2]- gt40p$lon)<1e-6))
  if (length(matches)>0)
  {
    #add counter to goodinds
    goodinds<-c(goodinds,counter)
  }
}
#throw out the rows of temp that are not in goodinds
pcpn <- pcpn[goodinds,]

```

<!---Chunk for Linear Regression--->
```{r echo=F, cache=T}
#Linear regression
#Dependent on finding locations with 40+ years of data
#Used to find intercept and slope
  #Will plot slopes on a map, larger slope = more warming

# temp data
#prepare rec. for saving slopes
  #could use gt40, would need new column 
gt40$slope<-NA

#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40))
  {
  #extract data from each weather station in new temp df
    #df with same columns as temp but only the rows for the WS on at this point in loop
    #calls the numbers of the rows that are for the ws at each step of the loop
  exrow<-as.numeric(gt40[counter,c("lat","lon")])
  
  temp.row<-which((abs(exrow[1]- temp$lat)<1e-6) & (abs(exrow[2]-temp$lon)<1e-6))
  #find all the rows of temp that match 
  temp.ws<-temp[temp.row,]
  
  #run linear regression
  model<-lm(value~year, temp.ws)
  slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
  
  #save slopes in gt40
  gt40$slope[counter]<-slope
}


#pcpn data
#prepare rec. for saving slopes
  #could use gt40, would need new column 
gt40p$slope<-NA

#for each weather station name/ row of gt40
for(counter in 1:nrow(gt40p))
  {
  #extract data from each weather station in new temp df
    #df with same columns as temp but only the rows for the WS on at this point in loop
    #calls the numbers of the rows that are for the ws at each step of the loop
  exrow<-as.numeric(gt40p[counter,c("lat","lon")])
  
  pcpn.row<-which((abs(exrow[1]- pcpn$lat)<1e-6) & (abs(exrow[2]-pcpn$lon)<1e-6))
  #find all the rows of temp that match 
  pcpn.ws<-pcpn[pcpn.row,]
  
  #run linear regression
  model<-lm(data~year, pcpn.ws)
  slope<-(coef(model)[2])#extract slope, call it the variable name "slope"
  
  #save slopes in gt40
  gt40p$slope[counter]<-slope
}
```


<!---Chunk for preparing for mapping (R maps package)--->
```{r echo=F, cache=T}
#Map of the US
cus<-map("state",".")

#Map of Hawaii
hi<-map("world","USA:Hawaii")

#Map of Alaska
ak<-map("world","USA:Alaska",xlim = c(-180,-120))
points(gt40$lon,gt40$lat)
```

<!-- <!---Chunk for Temp Map---> -->
<!-- ```{r echo=F, cache=T} -->
<!-- #Terry's approach -->
<!-- #make data frame with slopes and coordinates into spatial objects -->
<!--   #Produce a grid that creates a greater density of points between those -->
<!--   #use idw function to interpolate spatial object of the data frame  -->
<!--     #slopes as a function of coordinates -->
<!--   #Plot result of idw (spatial object) with spplot -->
<!--     #spplot(data = spatial df, zcol=slope) -->
<!--     #or spplot.grid(obj= new_df, zcol = "slope") -->
<!--     #will give a heat map of the grids  -->

<!-- #grid for hawaii -->
<!-- hix<-seq(-160.24345, -154.80420,by = .1) -->
<!-- hiy<-seq(18.96392, 22.22314, by = .1) -->
<!-- hid1<-expand.grid(x=hix,y=hiy) -->

<!-- #hawaii idw -->
<!-- hi.idw<-phylin::idw(values = gt40[,"slope"],coords = gt40[,c("lat","lon")], grid = hid1) -->

<!-- #slopes as a function of coordinates -->
<!-- sp::coordinates(hid1)<- c("x","y") -->

<!-- #convert to spatial points df -->
<!-- hid1$slope<-hi.idw -->

<!-- #Plot result of idw (spatial object) with spplot -->
<!-- spplot(obj = hid1, zcol = hid1@data$Z) -->



<!-- ``` -->

<!-- <!---Chunk for Temp Map using automap---> -->
<!-- ```{r echo=F, cache=T} -->

<!-- #load automap (can move this to beginning with rest of the packages if it is successful) -->
<!-- library(automap) -->

<!-- #Ordinary kriging  -->
<!-- #Need help understanding that these arguments mean in relation to my data https://www.r-bloggers.com/automatic-spatial-interpolation-with-r-the-automap-package/ -->




<!-- ``` -->